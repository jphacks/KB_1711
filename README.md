# サンプル（プロダクト名）
Emo_buddy

[![Product Name](https://raw.github.com/GabLeRoux/WebMole/master/ressources/WebMole_Youtube_Video.png)](https://www.youtube.com/channel/UC4PtjOfZTbVp9DwtJv82Lzg)

## 製品概要
### Emotion X Tech
利用者の感情・心境をより発信しやすく、理解されやすくするためのテクノロジー。
発話者の顔の表情には出ていない感情を表現するデバイス。

### 背景（製品開発のきっかけ、課題等）
私たちがコミュニケーションを取る際に、一般的にその人が話すこと（言語）よりも、見た目や表情（視覚情報）や声のトーン（聴覚情報）の方が人に影響を与えると言われている。また先行研究で文化や社会ごとに人に与える情報である視覚情報や聴覚情報の比率が異なることが分かっており、日本人は聴覚情報の比率が高く、声のトーンから相手の感情を理解し、欧米人は視覚情報の比率が高く、表情から相手の感情を理解すると考えられている。そしてこのズレこそが、異文化コミュニケーションにおいてうまく感情が伝わらない原因だと私たちは考え、声のトーンから発話者の感情の検知し、バッチ型のデバイスとして表現できるようにした。

顔の表情については、Ekman[]やBirdwhistell[]らが進めた生理的、あるいは心理的アプローチに基づく原理の究明が有名である。特に、Ekmanは６つの基本感情を定義しているための私たちのデバイスでも6種類の表情を現わせるようにした。

### 製品説明（具体的な製品の説明）
作成したバッチ型のデバイスは体の胸部や肩といった部分に身につけて、デバイスについているマイクから音声情報は身につけているiPhoneに送信し、iOSにて感情解析を行う。その後、感情解析した結果をデバイスに送り直し、デバイスの液晶にて表情を映し出すといったもの。

### 特長

#### 1. 特長1

#### 2. 特長2

#### 3. 特長3

### 解決出来ること
この製品を使うことによって、感情を表情として出すのが苦手な人がより感情を出しやすくするのを手助けたり、異文化コミュニケーションにおいて表情が表に出ていることによって誤解の少ないコミュニケーションを可能にしたいと考えている。

### 今後の展望
現在のところ、声のトーンだけで発話者の感情を推定して、デバイスは表情を推定しているために、声のトーンだけではなく、発話者の話した内容そのものも言語処理することによって、さらに発話者の感情検知の精度を上げていきたい。

## 開発内容・開発技術


### 活用した技術
* Bluetooth
* 
* 

#### フレームワーク・ライブラリ・モジュール
* 
* 

#### デバイス
*　iPhoneと私たちが作成したデバイスを作成し、
* 



### 独自開発技術（Hack Dayで開発したもの）
#### 2日間に開発した独自の機能・技術
* 独自で開発したものの内容をこちらに記載してください
* 特に力を入れた部分をファイルリンク、またはcommit_idを記載してください（任意）
